---
title: "Ames Housing Prices: Part IV - PC, PLS and Best Subset Regression "
author: "Sanjeev Gadre"
date: "June 28, 2019"
output: 
    md_document:
        toc: TRUE
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(warning = FALSE, echo = TRUE) #message = FALSE
```

Loading the required libraries.

```{r libraries, echo=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(glmnet)
library(gridExtra)
library(pls)
library(leaps)

```

### Getting the Data

1.  We start by getting the previously cleaned *train* subset.

```{r get-data}
train = readRDS("./RDA/train")

n = nrow(train)
p = ncol(train)-1
y = train$SalePrice %>% log()
```

### Introduction

1.  We will use the following 3 learning algorithms that help reduce the dimensionality of the train data:
    a.  Principal Component Regression
    b.  Partial Least Square Regression
    c.  Regresion using the best subset.
2.  We will use the *train-validate-test* strategy to fit an optimal model to the *train* data-set as well as estimate the likely test error.


### Principal Component Regression

1.  We use the `pls` library's inbuilt cross-validation feature for selection of optimal number of principal components.
2.  The train data-set will be divided into 2 subsets - **train** and **test** - in the ratio 70:30. The *test subset* will be used to estimate the likely test error for a model buit using the optimal number of principal components.

```{r pcr}
set.seed(1970)
fit = pcr(log(SalePrice)~., data = train, ncomp = p, center = TRUE, validation = "CV")

opt.z = fit$validation$PRESS %>% which.min()

est.test.err = 0
for (k in 1:5) {
    set.seed(k)
    indx = sample(1:n, 0.7*n)
    
    fit = pcr(log(SalePrice)~., data = train[indx, ], ncomp = opt.z)
    
    y.val.hat = predict(fit, newdata = train[-indx,], ncomp = opt.z)
    test.err = (y.val.hat - y[-indx])^2 %>% mean()
    
    est.test.err = est.test.err + test.err
}

est.test.err = round(est.test.err/5, digits = 4)

print(paste("The estimated mean squared test error for a principal component regression model =", est.test.err))
```

### Partial Least Square Regression

1.  We use the `pls` library's inbuilt cross-validation feature for selection of optimal number of partial least square directions.
2.  The train data-set will be divided into 2 subsets - **train** and **test** - in the ratio 70:30. The *test subset* will be used to estimate the likely test error for a model buit using the optimal number of partial least square directions.

```{r pls}
set.seed(1970)
fit = plsr(log(SalePrice)~., data = train, ncomp = p, center = TRUE, validation = "CV")

opt.z = fit$validation$PRESS %>% which.min()

est.test.err = 0
for (k in 1:5) {
    set.seed(k)
    indx = sample(1:n, 0.7*n)
    
    fit = plsr(log(SalePrice)~., data = train[indx, ], ncomp = opt.z)
    
    y.val.hat = predict(fit, newdata = train[-indx,], ncomp = opt.z)
    test.err = (y.val.hat - y[-indx])^2 %>% mean()
    
    est.test.err = est.test.err + test.err
}

est.test.err = round(est.test.err/5, digits = 4)

print(paste("The estimated mean squared test error for a partial least square regression model =", est.test.err))
```

### Best Subset Selection - Forward Selection

1.  We perform a 10-fold cross validation to select the optimal size of the subset of features.
2.  The train data-set will be divided into 2 subsets - **train** and **test** - in the ratio 70:30. The *test subset* will be used to estimate the likely test error for a model buit using the optimal size of subset of features.

```{r regsubsets-forward}
no.of.folds = 10
set.seed(1970)
indx = sample(1:no.of.folds, n, replace = TRUE)

est.val.err = rep(0, p)
for (i in 1:no.of.folds) {
    fit = regsubsets(log(SalePrice)~., data = train[indx != i, ], nvmax = p, method = "forward")
    
    test.mat = model.matrix(SalePrice~., data = train[indx == i,])
    
    for (j in 1:p) {
       coefj = coef(fit, id = j)
       y.val.hat = test.mat[, names(coefj)]%*%coefj
       val.err = (y.val.hat - y[indx == i])^2 %>% mean()
       est.val.err[j] = est.val.err[j] + val.err 
    }
    
}

est.val.err = est.val.err/no.of.folds

opt.z = which.min(est.val.err)

est.test.err = 0
for (k in 1:5) {
    set.seed(k)
    indx = sample(1:n, 0.7*n)
    
    fit = regsubsets(log(SalePrice)~., data = train[indx, ], nvmax = opt.z, method = "forward")
    coef.fit = coef(fit, id = opt.z)
    test.mat = model.matrix(SalePrice~., data = train[-indx,])
    
    y.val.hat = test.mat[, names(coef.fit)]%*%coef.fit
    test.err = (y.val.hat - y[-indx])^2 %>% mean()
    
    est.test.err = est.test.err + test.err
}

est.test.err = round(est.test.err/5, digits = 4)

print(paste("The estimated mean squared test error for a best subset (forward) selection model =", est.test.err))

```

### Best Subset Selection - Backward Selection

1.  We use the same strategy as for the *Forward Selection* algorithm.

```{r regsubsets-backward}
no.of.folds = 10
set.seed(1970)
indx = sample(1:no.of.folds, n, replace = TRUE)

est.val.err = rep(0, p)
for (i in 1:no.of.folds) {
    fit = regsubsets(log(SalePrice)~., data = train[indx != i, ], nvmax = p, method = "backward")
    
    test.mat = model.matrix(SalePrice~., data = train[indx == i,])
    
    for (j in 1:p) {
       coefj = coef(fit, id = j)
       y.val.hat = test.mat[, names(coefj)]%*%coefj
       val.err = (y.val.hat - y[indx == i])^2 %>% mean()
       est.val.err[j] = est.val.err[j] + val.err 
    }
    
}

est.val.err = est.val.err/no.of.folds

opt.z = which.min(est.val.err)

est.test.err = 0
for (k in 1:5) {
    set.seed(k)
    indx = sample(1:n, 0.7*n)
    
    fit = regsubsets(log(SalePrice)~., data = train[indx, ], nvmax = opt.z, method = "backward")
    coef.fit = coef(fit, id = opt.z)
    test.mat = model.matrix(SalePrice~., data = train[-indx,])
    
    y.val.hat = test.mat[, names(coef.fit)]%*%coef.fit
    test.err = (y.val.hat - y[-indx])^2 %>% mean()
    
    est.test.err = est.test.err + test.err
}

est.test.err = round(est.test.err/5, digits = 4)

print(paste("The estimated mean squared test error for a best subset (backward) selection model =", est.test.err))

```

*Observations*
1.  The Principal Component Regression model underperforms the penalised regression models.
2.  The Partial Least Squares Regression models outperforms the penalised regression models; it currently is the best performing model.
3.  The Best Subset Selection Regression model underperforms all the models tried so far.


